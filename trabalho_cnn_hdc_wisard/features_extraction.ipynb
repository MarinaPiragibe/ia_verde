{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0433d25",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0aa61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms\n",
    "from modules import utils, globals\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24e794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # # Download latest version\n",
    "# path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c6feb",
   "metadata": {},
   "source": [
    "### Carregando modelo pré-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa4f86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marinapiragibe/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/marinapiragibe/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo 'resnet18_cifake_finetuned_float32.pth' carregado para avaliação de desempenho.\n",
      "Modelo pré-treinado carregado.\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.load_model_from_file(\"resnet18_cifake_finetuned_float32.pth\")\n",
    "print(\"Modelo pré-treinado carregado.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                     transforms.Resize(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                          std=[0.229, 0.224, 0.225])\n",
    "                  ])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=os.path.join(globals.DATASET_PATH, 'train'),\n",
    "    transform=transform\n",
    ")\n",
    "# Cria subsets para testar a lógica do modelo com um número menor do dataset (descomentar para usar)\n",
    "subset_train_indices = list(range(globals.NUM_SAMPLES_TRAIN_DEBUGGER))\n",
    "\n",
    "total_train_samples = len(train_dataset)\n",
    "num_train_to_select = min(globals.NUM_SAMPLES_TRAIN_DEBUGGER, total_train_samples)\n",
    "subset_train_indices = random.sample(range(total_train_samples), num_train_to_select)\n",
    "\n",
    "train_dataset_debugger = Subset(train_dataset, subset_train_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_debugger,\n",
    "    batch_size=globals.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef8105",
   "metadata": {},
   "source": [
    "### Removendo a última camada fc\n",
    "\n",
    "A última camada da CNN pré-treinada é removida, porque utilizaremos esse modelo para extrair as carcterísticas que servirão de entrada para outros modelos como HDC e Wisard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb45a87",
   "metadata": {},
   "source": [
    "### Extraindo as features e labels geradas pelo modelo\n",
    "\n",
    "Nessa parte são percorridos os dados do train_loader e extraídas as características com um feature_extractor. Em seguida, todos os batches são concatenados em arrays únicos e salvos como arquivos .npy. Isso permite reutilizar os dados processados sem precisar extraí-los novamente a cada execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a9c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125[0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1\n",
      " 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0\n",
      " 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0\n",
      " 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1\n",
      " 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1\n",
      " 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1\n",
      " 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0\n",
      " 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1\n",
      " 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0\n",
      " 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1\n",
      " 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1\n",
      " 1]\n",
      "Features salvas em 'features.npy' e labels em 'labels.npy\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k, batch in enumerate(train_loader):\n",
    "        print(f'\\r{k+1}/{len(train_loader)}', end='', flush=True) \n",
    "\n",
    "        dado, rotulo = batch\n",
    "        dado = dado.to(globals.DEVICE)\n",
    "        rotulo = rotulo.to(globals.DEVICE)\n",
    "        features = feature_extractor(dado)\n",
    "\n",
    "        features = features.view(features.size(0), -1)\n",
    "\n",
    "        all_features.append(features.cpu())\n",
    "        all_labels.append(rotulo)\n",
    "\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(f\"\\n{labels_array}\")\n",
    "\n",
    "\n",
    "np.save('features.npy', features_array)\n",
    "np.save('labels.npy', labels_array)\n",
    "\n",
    "print(\"Features salvas em 'features.npy' e labels em 'labels.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
