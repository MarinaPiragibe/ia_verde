{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfead85",
   "metadata": {},
   "source": [
    "## CNN: Fine-Tunning com HDC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93977e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e5039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import utils, globals\n",
    "import torch\n",
    "from modules import encoders\n",
    "from binhd.classifiers import BinHD\n",
    "from modules.cifake import Cifake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from modules.encoders import RecordEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6b71f",
   "metadata": {},
   "source": [
    "### Carregando features e labels do modelo pré-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b5f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features salvas em 'features.npy'\n",
      "Labels salvas em 'labels.npy'\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('features_labels.h5', 'r') as h5f:\n",
    "    features = h5f['features'][:]\n",
    "    labels = h5f['labels'][:]\n",
    "\n",
    "np.save('features.npy', features)\n",
    "np.save('labels.npy', labels)\n",
    "print(f\"Features salvas em '{'features.npy'}'\")\n",
    "print(f\"Labels salvas em '{'labels.npy'}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f46367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('features.npy', mmap_mode='r')\n",
    "labels = np.load('labels.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7904265",
   "metadata": {},
   "source": [
    "### Instanciando a classe Cifake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a25bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de samples: 10000\n",
      "Classes encontradas:         feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
      "0     3.566299  0.552224  0.323557  0.032866  0.075987  0.785853  0.072742   \n",
      "1     1.045814  0.843926  0.407755  0.868205  0.230863  0.250009  1.471078   \n",
      "2     0.727950  1.614394  0.743747  0.509086  0.833209  0.972774  3.097703   \n",
      "3     0.315343  0.429487  0.122323  0.047726  0.000000  0.120156  0.363570   \n",
      "4     1.472784  1.147796  0.094612  2.631185  0.294509  1.003880  0.260441   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.224842  0.840820  0.170251  0.691287  2.081031  0.373396  1.113104   \n",
      "9996  2.091663  0.845579  0.376688  0.166369  0.096375  0.246661  0.662203   \n",
      "9997  1.052457  0.773135  0.966160  1.023654  1.183315  1.353256  0.256763   \n",
      "9998  0.564769  0.919356  1.239231  0.629036  3.866544  0.299065  0.863112   \n",
      "9999  0.059795  1.072452  0.775502  1.368680  1.582446  1.353043  0.481853   \n",
      "\n",
      "        feat_7    feat_8    feat_9  ...  feat_502  feat_503  feat_504  \\\n",
      "0     0.430246  3.011581  0.541334  ...  1.075760  1.866228  1.698461   \n",
      "1     0.401573  1.120712  0.296820  ...  1.549218  0.112919  0.409680   \n",
      "2     0.856852  0.392211  0.497553  ...  1.936148  0.236827  0.126459   \n",
      "3     0.972941  0.374334  0.045153  ...  0.401245  0.216099  0.954809   \n",
      "4     0.188374  0.252188  0.116283  ...  1.274427  0.390031  1.014450   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "9995  0.702474  0.464294  0.446795  ...  2.045690  0.998949  0.040296   \n",
      "9996  0.751524  0.896413  1.282184  ...  0.000000  2.456021  1.374226   \n",
      "9997  1.154203  0.404425  1.321546  ...  0.088256  1.339133  0.540117   \n",
      "9998  1.276195  0.470198  0.384499  ...  0.503096  1.390042  0.374287   \n",
      "9999  0.746235  0.422206  1.556111  ...  1.730223  0.704920  0.264582   \n",
      "\n",
      "      feat_505  feat_506  feat_507  feat_508  feat_509  feat_510  feat_511  \n",
      "0     1.535567  2.142946  0.970084  0.649176  2.701420  1.189620  0.041466  \n",
      "1     0.466873  1.910287  0.774954  0.177633  0.016185  1.247898  0.194067  \n",
      "2     1.114954  1.340739  0.860062  0.938335  0.031970  0.838256  0.368288  \n",
      "3     1.018278  2.363567  0.323952  0.596797  1.499665  2.084581  0.711530  \n",
      "4     0.242378  0.651822  2.561891  0.155079  3.684232  1.895504  1.032368  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "9995  0.725913  0.047029  0.173252  0.496561  1.077583  0.970296  0.261744  \n",
      "9996  1.266888  2.734816  0.333946  2.784367  1.674627  2.968245  1.686557  \n",
      "9997  0.061263  0.820167  1.378379  0.824185  0.030227  0.751393  1.313130  \n",
      "9998  0.023753  0.383178  1.300476  0.105420  1.642466  1.276096  0.189980  \n",
      "9999  0.263557  0.100264  0.585158  0.322956  0.778518  0.663201  0.269720  \n",
      "\n",
      "[10000 rows x 512 columns]\n"
     ]
    }
   ],
   "source": [
    "cifake = Cifake()\n",
    "# Verifica as amostras e classes\n",
    "print(f\"Número de samples: {len(cifake.samples)}\")\n",
    "print(f\"Classes encontradas: {cifake.features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeafde15",
   "metadata": {},
   "source": [
    "### Valores mínimo e máximo das features numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3599a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 10.250330924987793\n"
     ]
    }
   ],
   "source": [
    "min_val, max_val = cifake.get_min_max_values()\n",
    "print(min_val, max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd362225",
   "metadata": {},
   "source": [
    "### Definindo hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1f5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 10000\n",
    "num_levels = 100\n",
    "low = min_val\n",
    "high = max_val\n",
    "oper = \"bind\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdfda5",
   "metadata": {},
   "source": [
    "### Definindo X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff67439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 512)\n",
      "[dtype('float32')]\n"
     ]
    }
   ],
   "source": [
    "X = cifake.features\n",
    "print(X.shape)\n",
    "print(X.dtypes.unique())\n",
    "\n",
    "y = cifake.labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = torch.tensor(le.fit_transform(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a0124",
   "metadata": {},
   "source": [
    "### Carregando o modelo BinHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07d5d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_0      float32\n",
      "feat_1      float32\n",
      "feat_2      float32\n",
      "feat_3      float32\n",
      "feat_4      float32\n",
      "             ...   \n",
      "feat_507    float32\n",
      "feat_508    float32\n",
      "feat_509    float32\n",
      "feat_510    float32\n",
      "feat_511    float32\n",
      "Length: 512, dtype: object\n"
     ]
    }
   ],
   "source": [
    "model = BinHD(dimension, cifake.num_classes)\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932396e2",
   "metadata": {},
   "source": [
    "### Record Encoder\n",
    "\n",
    "O RecordEncoder é responsável por codificar entradas contínuas em representações hiperdimensionais binárias ou densas. Ele recebe como entrada a dimensionalidade de saída (out_features), que define o tamanho dos vetores hiperdimensionais gerados. Além disso, utiliza o parâmetro size, que representa o número de atributos de entrada, e levels, que determina quantos níveis serão usados para discretizar os dados. Os parâmetros low e high definem os limites inferior e superior dos valores de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de23842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_encoder = RecordEncoder(\n",
    "            out_features=dimension,\n",
    "            size=X.shape[1], \n",
    "            levels=num_levels,\n",
    "            low=low,\n",
    "            high=high\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5957b81",
   "metadata": {},
   "source": [
    "A função run_encoders processa os dados em lotes, onde os dados de entrada são convertidos em tensores, codificados pelo record_encoder, e armazenados em uma lista para serem concatenados no final, retornando todos os vetores codificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444a99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_encoders(X, device, record_encoder):\n",
    "\n",
    "    assert isinstance(X, pd.DataFrame), \"X precisa ser um DataFrame\"\n",
    "    assert not X.isnull().values.any(), \"X contém valores NaN\"\n",
    "    assert device in [\"cuda\", \"cpu\"], f\"Dispositivo inválido: {device}\"\n",
    "\n",
    "    encoded_batches = []\n",
    "\n",
    "    record_encoder.to(device)\n",
    "    record_encoder.eval()\n",
    "\n",
    "    num_samples = len(X)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_samples, globals.BATCH_SIZE):\n",
    "            end = min(i + globals.BATCH_SIZE, num_samples)\n",
    "\n",
    "            x_batch_np = X.iloc[i:end].values.astype(np.float32)\n",
    "\n",
    "            try:\n",
    "                x_batch_tensor = torch.tensor(x_batch_np).to(device)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao converter batch {i}-{end} para tensor: {e}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                encoded = record_encoder(x_batch_tensor)\n",
    "                encoded_batches.append(encoded.cpu())\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao codificar batch {i}-{end}: {e}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\rProcessando amostras {i} até {end}\", end='', flush=True)\n",
    "\n",
    "    if encoded_batches != []:\n",
    "        encoded_all = torch.cat(encoded_batches, dim=0)\n",
    "    else:\n",
    "        raise RuntimeError(\"Nenhum batch foi codificado com sucesso.\")\n",
    "\n",
    "    return encoded_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8cd99",
   "metadata": {},
   "source": [
    "### Separando em treino e teste e rodando o encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54edbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando amostras 9992 até 10000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1024/2993563554.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_encoded = torch.tensor(y_encoded).to(globals.DEVICE)\n"
     ]
    }
   ],
   "source": [
    "X_record_encoder = run_encoders(X, globals.DEVICE, record_encoder)\n",
    "labels = torch.tensor(y).to(globals.DEVICE)\n",
    "\n",
    "y_encoded = torch.tensor(y_encoded).to(globals.DEVICE)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_record_encoder, labels, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a5cc35",
   "metadata": {},
   "source": [
    "### Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd0ad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1024/3941384730.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  y_pred_np = np.array(predictions)\n",
      "/tmp/ipykernel_1024/3941384730.py:6: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  y_test_np = np.array(y_test)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_test.to(torch.int8))  \n",
    "\n",
    "y_pred_np = np.array(predictions)\n",
    "y_test_np = np.array(y_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9ce25",
   "metadata": {},
   "source": [
    "### Resultados e Conclusões\n",
    "\n",
    "O modelo HDC (BinHD) foi usado como classificador final sobre features previamente extraídas de uma CNN pré-treinada. Para realizar uma comparação justa tentou-se utilizar 10000 imagens como entrada mas por limitações da máquina que possui 8Gbytes de memória RAM não foi possível e a entrada foi diminuída para 5000 imagens.\n",
    "\n",
    "O modelo HDC teve uma piora considerável em relação à CNN original. Isso pode ser devido a ajustes dos hiperparâmetros, mas ao mesmo tempo não creio que justifica um resultado tão baixo, talvez existam erros na implementação do modelo.\n",
    "\n",
    "As dificuldades para esse modelo foram as mesmas das do trabalho anterior, limitações da máquina em questão. Por ter apenas 8 Gbytes de RAM foram necessárias abordagem para que o Kernel não quebrasse e parasse a execução. Dentre essas abordagens o processamento em batch e utilizar uma biblioteca que salvasse parcialmente os arquivos na parte da extração das features. Quanto ao treinamento, mesmo que tenham sido utilizadas metade das entradas do outro modelo a execução foi mais rápida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d849518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.00      0.01      1487\n",
      "           1       0.50      1.00      0.67      1513\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.50      0.34      3000\n",
      "weighted avg       0.59      0.51      0.34      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_np, y_pred_np,\n",
    "    labels=np.unique(y_test)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
